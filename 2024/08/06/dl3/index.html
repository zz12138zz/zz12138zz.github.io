<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="keywords" content="Hexo Theme Redefine"><meta name="author" content="Yizumi Konata"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="canonical" href="http://example.com/2024/08/06/dl3/"><meta name="robots" content="index,follow"><meta name="googlebot" content="index,follow"><meta name="revisit-after" content="1 days"><meta name="description" content="最近看到一个系列的深度学习入门博客，感觉写的很好，于是自己整理记录一下自己的学习历程，算是转载吧"><meta property="og:type" content="article"><meta property="og:title" content="快速上手深度学习项目(三)"><meta property="og:url" content="http://example.com/2024/08/06/dl3/index.html"><meta property="og:site_name" content="纯路人的博客"><meta property="og:description" content="最近看到一个系列的深度学习入门博客，感觉写的很好，于是自己整理记录一下自己的学习历程，算是转载吧"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2024-08-06T08:49:23.000Z"><meta property="article:modified_time" content="2024-09-04T07:39:52.081Z"><meta property="article:author" content="Yizumi Konata"><meta property="article:tag" content="技术学习"><meta name="twitter:card" content="summary"><link rel="icon" type="image/png" href="https://zz12138img.oss-cn-beijing.aliyuncs.com/%E7%85%8E%E9%B8%A1%E8%9B%8B.png" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="https://zz12138img.oss-cn-beijing.aliyuncs.com/%E7%85%8E%E9%B8%A1%E8%9B%8B.png"><meta name="theme-color" content="#1890ff"><link rel="shortcut icon" href="https://zz12138img.oss-cn-beijing.aliyuncs.com/%E7%85%8E%E9%B8%A1%E8%9B%8B.png"><title>快速上手深度学习项目(三) - 纯路人的博客</title><link rel="stylesheet" href="/fonts/Chillax/chillax.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/assets/build/styles.css"><link rel="stylesheet" href="/fonts/GeistMono/geist-mono.css"><link rel="stylesheet" href="/fonts/Geist/geist.css"><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap" rel="stylesheet"><script src="/js/libs/anime.min.js"></script><script id="hexo-configurations">window.config={hostname:"example.com",root:"/",language:"en",path:"search.xml"},window.theme={articles:{style:{font_size:"16px",line_height:1.5,image_border_radius:"14px",image_alignment:"center",image_caption:!1,link_icon:!0,title_alignment:"left",headings_top_spacing:{h1:"5rem",h2:"4rem",h3:"2.8rem",h4:"2.5rem",h5:"2.2rem",h6:"2rem"}},word_count:{enable:!0,count:!0,min2read:!0},author_label:{enable:!0,auto:!1,list:[]},code_block:{copy:!0,style:"mac",highlight_theme:{light:"github",dark:"vs2015"},font:{enable:!1,family:null,url:null}},toc:{enable:!0,max_depth:3,number:!1,expand:!0,init_open:!0},copyright:{enable:!0,default:"cc_by_nc_sa"},lazyload:!0,recommendation:{enable:!1,title:"推荐阅读",limit:3,mobile_limit:2,placeholder:"/images/wallhaven-wqery6-light.webp",skip_dirs:[]}},colors:{primary:"#1890ff",secondary:null,default_mode:"light"},global:{fonts:{chinese:{enable:!1,family:null,url:null},english:{enable:!1,family:null,url:null},title:{enable:!1,family:null,url:null}},content_max_width:"1000px",sidebar_width:"210px",hover:{shadow:!0,scale:!0},scroll_progress:{bar:!0,percentage:!0},website_counter:{url:"https://cn.vercount.one/js",enable:!0,site_pv:!0,site_uv:!0,post_pv:!0},single_page:!0,preloader:{enable:!0,custom_message:null},open_graph:!0,google_analytics:{enable:!1,id:null}},home_banner:{enable:!0,style:"fixed",image:{light:"/images/monika.webp",dark:"/images/monika.webp"},title:"为了幸福地生活，我就必须与世界保持一致",subtitle:{text:["Down the rabbit hole..."],hitokoto:{enable:!1,show_author:!1,api:"https://v1.hitokoto.cn"},typing_speed:80,backing_speed:100,starting_delay:500,backing_delay:1500,loop:!0,smart_backspace:!0},text_color:{light:"#000",dark:"#fff"},text_style:{title_size:"2.8rem",subtitle_size:"1.5rem",line_height:1.2},custom_font:{enable:!0,family:"Noto Sans SC",url:"https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap"},social_links:{enable:!0,style:"default",links:{github:"https://github.com/zz12138zz",instagram:null,zhihu:null,twitter:null,email:"954988021@qq.com"},qrs:{weixin:null}}},plugins:{feed:{enable:!1},aplayer:{enable:!0,type:"fixed",audios:[{name:"テルーの呗",artist:"手嶌葵",url:"https://zz12138music.oss-cn-beijing.aliyuncs.com/1.mp3",cover:"https://zz12138music.oss-cn-beijing.aliyuncs.com/1.png",lrc:null},{name:"勘ぐれい",artist:"ずっと真夜中でいいのに",url:"https://zz12138music.oss-cn-beijing.aliyuncs.com/2.m4a",cover:"https://zz12138music.oss-cn-beijing.aliyuncs.com/2.jpg"}]},mermaid:{enable:!1,version:"9.3.0"}},version:"2.7.0",navbar:{auto_hide:!1,color:{left:"#f78736",right:"#367df7",transparency:35},width:{home:"1200px",pages:"1000px"},links:{Home:{path:"/",icon:"fa-regular fa-house"},Archives:{path:"/archives",icon:"fa-regular fa-archive"},Categories:{icon:"fa-regular fa-folder",path:"/categories/"},Tags:{icon:"fa-regular fa-tags",path:"/tags/"},About:{icon:"fa-regular fa-user",path:"/about/"}},search:{enable:!0,preload:!0},tags:{Tags:{icon:"fa-solid fa-tags",path:"/tags/"}},categories:{Categories:{icon:"fa-solid fa-folder",path:"/categories/"}}},page_templates:{friends_column:2,tags_style:"blur"},home:{sidebar:{enable:!0,position:"left",first_item:"menu",announcement:null,show_on_mobile:!0,links:null},article_date_format:"auto",excerpt_length:200,categories:{enable:!0,limit:3},tags:{enable:!0,limit:3}},footerStart:"2022/8/17 11:45:14"},window.lang_ago={second:"%s seconds ago",minute:"%s minutes ago",hour:"%s hours ago",day:"%s days ago",week:"%s weeks ago",month:"%s months ago",year:"%s years ago"},window.data={masonry:!1}</script><link rel="stylesheet" href="/fontawesome/fontawesome.min.css"><link rel="stylesheet" href="/fontawesome/brands.min.css"><link rel="stylesheet" href="/fontawesome/solid.min.css"><link rel="stylesheet" href="/fontawesome/regular.min.css"><meta name="generator" content="Hexo 7.2.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span></div><style>:root{--preloader-background-color:#fff;--preloader-text-color:#000}@media (prefers-color-scheme:dark){:root{--preloader-background-color:#202124;--preloader-text-color:#fff}}@media (prefers-color-scheme:light){:root{--preloader-background-color:#fff;--preloader-text-color:#000}}@media (max-width:600px){.ml13{font-size:2.6rem!important}}.preloader{display:flex;flex-direction:column;gap:1rem;align-items:center;justify-content:center;position:fixed;padding:12px;top:0;right:0;bottom:0;left:0;width:100vw;height:100vh;background-color:var(--preloader-background-color);z-index:1100;transition:opacity .2s ease-in-out}.ml13{font-size:3.2rem;color:var(--preloader-text-color);letter-spacing:-1px;font-weight:500;font-family:Chillax-Variable,sans-serif;text-align:center}.ml13 .word{display:inline-flex;flex-wrap:wrap;white-space:nowrap}.ml13 .letter{display:inline-block;line-height:1em}</style><div class="preloader"><h2 class="ml13">纯路人的博客</h2><script>var textWrapper = document.querySelector('.ml13');
        // Split text into words
        var words = textWrapper.textContent.trim().split(' ');

        // Clear the existing content
        textWrapper.innerHTML = '';

        // Wrap each word and its letters in spans
        words.forEach(function(word) {
            var wordSpan = document.createElement('span');
            wordSpan.classList.add('word');
            wordSpan.innerHTML = word.replace(/\S/g, "<span class='letter'>$&</span>");
            textWrapper.appendChild(wordSpan);
            textWrapper.appendChild(document.createTextNode(' ')); // Add space between words
        });

        var animation = anime.timeline({loop: true})
            .add({
                targets: '.ml13 .letter',
                translateY: [40,0],
                translateZ: 0,
                opacity: [0,1],
                filter: ['blur(5px)', 'blur(0px)'], // Starting from blurred to unblurred
                easing: "easeOutExpo",
                duration: 1400,
                delay: (el, i) => 300 + 30 * i,
            }).add({
                targets: '.ml13 .letter',
                translateY: [0,-40],
                opacity: [1,0],
                filter: ['blur(0px)', 'blur(5px)'], // Ending from unblurred to blurred
                easing: "easeInExpo",
                duration: 1200,
                delay: (el, i) => 100 + 30 * i,
                complete: function() {
                    hidePreloader(); // Call hidePreloader after the animation completes
                }
            });

        let themeStatus = JSON.parse(localStorage.getItem('REDEFINE-THEME-STATUS'))?.isDark;

        // If the theme status is not found in local storage, check the preferred color scheme
        if (themeStatus === undefined || themeStatus === null) {
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                themeStatus = 'dark';
            } else {
                themeStatus = 'light';
            }
        }

        // Now you can use the themeStatus variable in your code
        if (themeStatus) {
            document.documentElement.style.setProperty('--preloader-background-color', '#202124');
            document.documentElement.style.setProperty('--preloader-text-color', '#fff');
        } else {
            document.documentElement.style.setProperty('--preloader-background-color', '#fff');
            document.documentElement.style.setProperty('--preloader-text-color', '#000');
        }

        window.addEventListener('load', function () {
            setTimeout(hidePreloader, 5000); // Call hidePreloader after 5000 milliseconds if not already called by animation
        });

        function hidePreloader() {
            var preloader = document.querySelector('.preloader');
            preloader.style.opacity = '0';
            setTimeout(function () {
                preloader.style.display = 'none';
            }, 200);
        }</script></div><main class="page-container" id="swup"><div class="main-content-container"><div class="main-content-header"><header class="navbar-container px-6 md:px-12"><div class="navbar-content"><div class="left"><a class="logo-image" href="/"><img src="https://zz12138img.oss-cn-beijing.aliyuncs.com/%E7%85%8E%E9%B8%A1%E8%9B%8B.png"> </a><a class="logo-title" href="/">纯路人的博客</a></div><div class="right"><div class="desktop"><ul class="navbar-list"><li class="navbar-item"><a href="/"><i class="fa-regular fa-house fa-fw"></i> HOME</a></li><li class="navbar-item"><a href="/archives"><i class="fa-regular fa-archive fa-fw"></i> ARCHIVES</a></li><li class="navbar-item"><a href="/categories/"><i class="fa-regular fa-folder fa-fw"></i> CATEGORIES</a></li><li class="navbar-item"><a href="/tags/"><i class="fa-regular fa-tags fa-fw"></i> TAGS</a></li><li class="navbar-item"><a href="/about/"><i class="fa-regular fa-user fa-fw"></i> ABOUT</a></li><li class="navbar-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div><div class="icon-item navbar-bar"><div class="navbar-bar-middle"></div></div></div></div></div><div class="navbar-drawer h-screen w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between"><ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start"><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/"><span>HOME </span><i class="fa-regular fa-house fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/archives"><span>ARCHIVES </span><i class="fa-regular fa-archive fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/categories/"><span>CATEGORIES </span><i class="fa-regular fa-folder fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/tags/"><span>TAGS </span><i class="fa-regular fa-tags fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/about/"><span>ABOUT </span><i class="fa-regular fa-user fa-sm fa-fw"></i></a></li></ul><div class="statistics flex justify-around my-2.5"><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">13</div><div class="label text-third-text-color text-sm">Tags</div></a><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">3</div><div class="label text-third-text-color text-sm">Categories</div></a><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">16</div><div class="label text-third-text-color text-sm">Posts</div></a></div></div><div class="window-mask"></div></header></div><div class="main-content-body"><div class="main-content"><div class="post-page-container flex relative justify-between box-border w-full h-full"><div class="article-content-container"><div class="article-title relative w-full"><div class="w-full flex items-center pt-6 justify-start"><h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">快速上手深度学习项目(三)</h1></div></div><div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8"><div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]"><img src="https://zz12138img.oss-cn-beijing.aliyuncs.com/konata.png"></div><div class="info flex flex-col justify-between"><div class="author flex items-center"><span class="name text-default-text-color text-lg font-semibold">Yizumi Konata</span> <span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv3</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-pen-fancy"></i>&nbsp; <span class="desktop">2024-08-06 16:49:23</span> <span class="mobile">2024-08-06 16:49:23</span> <span class="hover-info">Created</span> </span><span class="article-date article-meta-item"><i class="fa-regular fa-wrench"></i>&nbsp; <span class="desktop">2024-09-04 15:39:52</span> <span class="mobile">2024-09-04 15:39:52</span> <span class="hover-info">Updated</span> </span><span class="article-categories article-meta-item"><i class="fa-regular fa-folders"></i>&nbsp;<ul><li><a href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fa-regular fa-tags"></i>&nbsp;<ul><li><a href="/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>&nbsp;</li></ul></span><span class="article-pv article-meta-item"><i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8"><h1 id="全连接神经网络pytorch">全连接神经网络（pytorch）</h1><p>pytorch以及更底层的conda、cuda怎么安装就不介绍了，要说我也不是很装的来，反正有什么问题就上网搜吧。</p><p>在PyTorch中，所有参与运算的张量都用同一个类表示，其类型名叫做<code>Tensor</code>，也就是<code>torch.Tensor</code>。而在构建张量时，我们一般要用<code>torch.tensor</code>这个函数，其可以传入一个列表。<code>Tensor</code>和<code>np.ndarray</code>用法几乎一模一样。两者之间可以互相转换</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##  下面两种方法都不创建新的内存空间</span></span><br><span class="line">array2tensor=torch.from_numpy(numpy_data)<span class="comment">#numpy array-&gt;torch tensor，其参数必须是数组形式</span></span><br><span class="line">tensor2array=torch_data.numpy()      <span class="comment">#torch tensor-&gt;numpy array</span></span><br></pre></td></tr></table></figure></div><p>这里有一个要注意的点是<code>torch.Tensor</code>是一个类型名，意味着他也可以是一个构造函数，而<code>torch.tensor</code>、<code>torch.from_numpy</code>等是一个工厂函数。构造函数在构造一个张量时的类型使用全局默认值，而工厂函数则根据输入推断数据类型，所以创建<code>tensor</code>建议统一使用<code>torch.tensor</code>,这会创建一块内存区域，如果不想创建内存区域的话可以使用<code>torch.as_tensor</code></p><p>那既然pytorch的核心数据结构与numpy这么像，为什么还要pytorch呢？这个问题的答案网上一搜一大堆，最根本的点在于pytorch会维护计算图，并根据为每一个（需要梯度计算的）<code>Tensor</code>自动计算梯度，这也就是我们为什么说他是框架，框架就是干一些脏活累活的嘛，就像你用springboot的时候就几乎不需要你手动监听管理socket了，你使用pytorch，就不需要自己动手计算梯度了。</p><h2 id="用pytorch实现多分类的神经网络矩阵乘">用pytorch实现多分类的神经网络（矩阵乘）</h2><p>其实这一节只是将ndarray换成了Tensor，其他几乎没区别，本节作者使用的是点集分类任务，我这边直接贴作者的代码，然后在关键地方解释一下</p><p>本项目中，我们要用到一个平面点数据集。在平面上，有三种颜色不同的点。我们希望用PyTorch编写的神经网络能够区分这三种点。这个点是作者随机生成的，有兴趣可以看<a class="link" target="_blank" rel="noopener" href="https://github.com/SingleZombie/DL-Demos/blob/master/dldemos/MulticlassClassification/points_classification.py">源代码 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。使用下面的代码生成400个点，x的形状为<code>[2,400]</code>，y的形状为<code>[1,400]</code></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y = generate_points(<span class="number">400</span>)</span><br></pre></td></tr></table></figure></div><p>在计算损失函数时，PyTorch默认标签<code>Y</code>是一个一维整形数组。而我们之前都会把<code>Y</code>预处理成<code>[1, m]</code>的张量。因此，这里要先做一个维度转换，再转张量。当然你先转张量，然后再调用<code>squeeze(0)</code>也是一样的，<code>Tensor</code>的删除单维度的方法也是<code>squeeze</code>，并且也可以用方法和全局函数两种方式调用，即<code>t.squeeze()</code>和<code>torch.squeeze(t)</code>是一样的。不过这里提一点，<code>Tensor</code>增加维度的函数名称叫做<code>unsqueeze</code>而不是numpy的<code>expand_dim</code></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_Y_pt = torch.tensor(train_Y.squeeze(<span class="number">0</span>), dtype=torch.long)</span><br></pre></td></tr></table></figure></div><p>然后定义网络。初始化函数如下。</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MulticlassClassificationNet</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, neuron_cnt: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        self.num_layer = <span class="built_in">len</span>(neuron_cnt) - <span class="number">1</span></span><br><span class="line">        self.neuron_cnt = neuron_cnt</span><br><span class="line">        self.W = []</span><br><span class="line">        self.b = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layer):</span><br><span class="line">            new_W = torch.empty(neuron_cnt[i + <span class="number">1</span>], neuron_cnt[i]) <span class="comment">#torch.empty创建未初始化的Tensor</span></span><br><span class="line">            new_b = torch.empty(neuron_cnt[i + <span class="number">1</span>], <span class="number">1</span>)</span><br><span class="line">            torch.nn.init.kaiming_normal_(new_W, nonlinearity=<span class="string">'relu'</span>)<span class="comment">#torch内置He Initialization函数，</span></span><br><span class="line">            torch.nn.init.kaiming_normal_(new_b, nonlinearity=<span class="string">'relu'</span>)</span><br><span class="line">            <span class="comment">#torch.nn.Parameter将传入的参数设置为可学习更新的参数，也就是让new_W和new_b参与梯度的计算</span></span><br><span class="line">            <span class="comment">#同时将张量注册为模型的参数</span></span><br><span class="line">            <span class="comment">#你可以理解为torch.nn.Parameter就是将参数设置为需要计算梯度的Tensor</span></span><br><span class="line">            self.W.append(torch.nn.Parameter(new_W))</span><br><span class="line">            self.b.append(torch.nn.Parameter(new_b))</span><br><span class="line">        self.trainable_vars = self.W + self.b</span><br><span class="line">        self.loss_fn = torch.nn.CrossEntropyLoss()<span class="comment">#torch内置交叉熵损失函数，</span></span><br><span class="line">       </span><br></pre></td></tr></table></figure></div><p>接下来编写前向传播函数和损失函数</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">    A = X</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layer):</span><br><span class="line">        Z = torch.matmul(self.W[i], A) + self.b[i]</span><br><span class="line">        <span class="keyword">if</span> i == self.num_layer - <span class="number">1</span>:</span><br><span class="line">            A = F.softmax(Z, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            A = F.relu(Z)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, Y, Y_hat</span>):</span><br><span class="line">    <span class="keyword">return</span> self.loss_fn(Y_hat.T, Y)</span><br></pre></td></tr></table></figure></div><p>注意前向传播函数里面不需要缓存那些计算梯度用到的变量了，这些脏活pytorch会帮我们做的，这个<code>F</code>是作者导入的<code>torch.nn.functional</code>,我代码是直接抄的，保留作者的写法。常用的一些函数在<code>torch.nn.functional</code>中基本都实现了，可以直接调用。</p><p>关于这个<code>torch.nn.functional</code>和<code>torch.nn</code>两个模块，其实也可以说道说道，基本上<code>torch.nn</code>中有的模块，<code>torch.nn.functional</code>中都有其函数实现，通常情况下<code>torch.nn</code>用于创建可学习的模块，也就是神经网络的参数，<code>torch.nn.functional</code>只是参与一下计算，里面没有可学习的参数。具体的区别有兴趣可以去搜一下。</p><p>最后是训练代码<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: MulticlassClassificationNet,</span></span><br><span class="line"><span class="params">          X,</span></span><br><span class="line"><span class="params">          Y,</span></span><br><span class="line"><span class="params">          step,</span></span><br><span class="line"><span class="params">          learning_rate,</span></span><br><span class="line"><span class="params">          print_interval=<span class="number">100</span></span>):</span><br><span class="line">    optimizer = torch.optim.Adam(model.trainable_vars, learning_rate)</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(step):</span><br><span class="line">        Y_hat = model.forward(X)</span><br><span class="line">        cost = model.loss(Y, Y_hat)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        cost.backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure></div><p></p><p>对比上一节的训练代码</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(total_epoch):</span><br><span class="line">    <span class="keyword">for</span> mini_batch_X, mini_batch_Y <span class="keyword">in</span> mini_batch_XYs:</span><br><span class="line">        mini_batch_Y_hat = model.forward(mini_batch_X)</span><br><span class="line">        model.backward(mini_batch_Y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        optimizer.add_grad(model.get_grad_dict())</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    currrent_epoch = optimizer.epoch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> currrent_epoch % print_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># print loss</span></span><br><span class="line">        ...</span><br><span class="line">     optimizer.increase_epoch()</span><br></pre></td></tr></table></figure></div><p>可以看到整体流程是差不多的，对每一步（当然这里没有batch了，引入batch无非就是你循环改一下，不影响训练流程）先前向传播，然后反向得到梯度，最后使用优化器更新参数，不过pytorch的写法里梯度是通过loss回传的，这样写我认为更直观。</p><p>执行完<code>cost = model.loss(Y, Y_hat)</code>，整个计算图就已经构造完成了。我们调用<code>optimizer.zero_grad()</code>清空优化器，用<code>cost.backward()</code>自动完成反向传播并记录梯度，之后用<code>optimizer.step()</code>完成一步梯度下降。</p><p>主函数里的训练代码就很简单了，不多说<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n_x = <span class="number">2</span></span><br><span class="line">neuron_list = [n_x, <span class="number">10</span>, <span class="number">10</span>, <span class="number">3</span>]</span><br><span class="line">model = MulticlassClassificationNet(neuron_list)</span><br><span class="line">train(model, train_X_pt, train_Y_pt, <span class="number">5000</span>, <span class="number">0.001</span>, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure></div><p></p><h2 id="用pytorch实现多分类的神经网络模块化">用pytorch实现多分类的神经网络（模块化）</h2><p>上面用pytorch，使用numpy手搓的思路实现了一个多分类神经网络。实际上我们一般写pytorch的思路并不是抄公式，而是使用现成的模块搭积木。比如上面的人物，不就是要搭建<code>len(neuron_cnt) - 1</code>个线性层吗，所以正常人写的代码应该是下面的</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MulticlassClassificationNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, neuron_cnt: <span class="built_in">list</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>(MulticlassClassificationNet, self).__init__()</span><br><span class="line">        layers = []</span><br><span class="line">        self.num_layer = <span class="built_in">len</span>(neuron_cnt) - <span class="number">1</span></span><br><span class="line">        <span class="comment"># 创建线性层</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layer):</span><br><span class="line">            layers.append(nn.Linear(neuron_cnt[i], neuron_cnt[i + <span class="number">1</span>]))</span><br><span class="line">        <span class="comment">#包装为一个nn.ModuleList，方便管理（比如直接注册，不需要torch.nn.Parameter，方便pytorch对参数序列化，不需要我们手动遍历列表，方便统一将参数移动到某个设备上等等）</span></span><br><span class="line">        self.layers = nn.ModuleList(layers)</span><br><span class="line">        self.loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        A = X</span><br><span class="line">        <span class="keyword">for</span> i, layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.layers):</span><br><span class="line">            A = layer(A)</span><br><span class="line">            <span class="keyword">if</span> i == self.num_layer - <span class="number">1</span>:</span><br><span class="line">                A = F.softmax(A, dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                A = F.relu(A)</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, Y, Y_hat</span>):</span><br><span class="line">        <span class="keyword">return</span> self.loss_fn(Y_hat, Y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, X, Y, return_loss=<span class="literal">False</span></span>):</span><br><span class="line">        Y_hat = self.forward(X)</span><br><span class="line">        Y_hat_predict = torch.argmax(Y_hat, dim=<span class="number">1</span>)</span><br><span class="line">        accuracy = (Y == Y_hat_predict).<span class="built_in">float</span>().mean()</span><br><span class="line">        <span class="keyword">if</span> return_loss:</span><br><span class="line">            loss = self.loss(Y, Y_hat)</span><br><span class="line">            <span class="keyword">return</span> accuracy, loss</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model: MulticlassClassificationNet, X, Y, step, learning_rate, print_interval=<span class="number">100</span></span>):</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), learning_rate)</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(step):</span><br><span class="line">        Y_hat = model(X)</span><br><span class="line">        cost = model.loss(Y, Y_hat)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        cost.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> s % print_interval == <span class="number">0</span>:</span><br><span class="line">            accuracy, loss = model.evaluate(X, Y, return_loss=<span class="literal">True</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f'Step: <span class="subst">{s}</span>'</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f'Accuracy: <span class="subst">{accuracy.item()}</span>'</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f'Train loss: <span class="subst">{loss.item()}</span>'</span>)</span><br><span class="line">            <span class="comment">#保存模型</span></span><br><span class="line">            torch.save(model.state_dict(), save_path)</span><br></pre></td></tr></table></figure></div><p>这里只用了最简单的线性层，其只需要输入和输出向量的维度即可。其实对于其他的模块，最重要的参数都是输入和输出的形状</p></div><div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8"><div class="article-copyright-info-container"><ul><li><strong>Title:</strong> 快速上手深度学习项目(三)</li><li><strong>Author:</strong> Yizumi Konata</li><li><strong>Created at :</strong> 2024-08-06 16:49:23</li><li><strong>Updated at :</strong> 2024-09-04 15:39:52</li><li><strong>Link:</strong> https://zz12138zz.github.io/2024/08/06/dl3/</li><li><strong>License: </strong>This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a>.</li></ul></div></div><ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden"><li class="tag-item mx-0.5"><a href="/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">#技术学习</a>&nbsp;</li></ul><div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8"><div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2"><a class="prev" rel="prev" href="/2024/09/04/dl4/"><span class="left arrow-icon flex justify-center items-center"><i class="fa-solid fa-chevron-left"></i> </span><span class="title flex justify-center items-center"><span class="post-nav-title-item">快速上手深度学习项目(四)</span> <span class="post-nav-item">Prev posts</span></span></a></div><div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2"><a class="next" rel="next" href="/2024/07/15/dl2/"><span class="title flex justify-center items-center"><span class="post-nav-title-item">快速上手深度学习项目(二)</span> <span class="post-nav-item">Next posts</span> </span><span class="right arrow-icon flex justify-center items-center"><i class="fa-solid fa-chevron-right"></i></span></a></div></div><div class="comment-container px-2 sm:px-6 md:px-8 pb-8"><div class="comments-container mt-10 w-full"><div id="comment-anchor" class="w-full h-2.5"></div><div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">Comments</div><div id="waline"></div><script type="module" data-swup-reload-script>import{init}from"/js/libs/waline.mjs";function loadWaline(){init({el:"#waline",serverURL:"https://waline233-blond.vercel.app",lang:"zh-CN",dark:'body[class~="dark-mode"]',reaction:!1,requiredMeta:["nick","mail"],emoji:[],recaptchaV3Key:"wasd"})}"undefined"!=typeof swup?loadWaline():window.addEventListener("DOMContentLoaded",loadWaline)</script></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><div class="toc-title">On this page</div><div class="page-title">快速上手深度学习项目(三)</div><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cpytorch"><span class="nav-text">全连接神经网络（pytorch）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A9%E9%98%B5%E4%B9%98"><span class="nav-text">用pytorch实现多分类的神经网络（矩阵乘）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9D%97%E5%8C%96"><span class="nav-text">用pytorch实现多分类的神经网络（模块化）</span></a></li></ol></li></ol></div></div></div></div></div></div><div class="main-content-footer"><footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color"><div class="info-container py-3 text-center"><div class="text-center">&copy; <span>2022</span> - 2024&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration:0.5s;color:#f54545"></i>&nbsp;&nbsp;<a href="/">Yizumi Konata</a><p class="post-count space-x-0.5"><span>16 posts in total</span></p></div><script data-swup-reload-script src="https://cn.vercount.one/js"></script><div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right"><span id="busuanzi_container_site_uv" class="lg:!block"><span class="text-sm">VISITOR COUNT</span> <span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" class="lg:!block"><span class="text-sm">TOTAL PAGE VIEWS</span> <span id="busuanzi_value_site_pv"></span></span></div><div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left"><span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span> <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.7.0</a></span></div><div>Blog up for <span class="odometer" id="runtime_days"></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec</div><script data-swup-reload-script>try{function odometer_init(){document.querySelectorAll(".odometer").forEach(e=>{new Odometer({el:e,format:"( ddd).dd",duration:200})})}odometer_init()}catch(e){}</script></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="article-tools-list"><li class="right-bottom-tools page-aside-toggle"><i class="fa-regular fa-outdent"></i></li><li class="go-comment"><i class="fa-regular fa-comments"></i></li></ul></div></div><div class="right-side-tools-container"><div class="side-tools-container"><ul class="hidden-tools-list"><li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center"><i class="fa-regular fa-magnifying-glass-plus"></i></li><li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center"><i class="fa-regular fa-magnifying-glass-minus"></i></li><li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center"><i class="fa-regular fa-moon"></i></li><li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center"><i class="fa-regular fa-arrow-down"></i></li></ul><ul class="visible-tools-list"><li class="right-bottom-tools toggle-tools-list flex justify-center items-center"><i class="fa-regular fa-cog fa-spin"></i></li><li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="image-viewer-container"><img src=""></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fa-solid fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa-solid fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="/js/libs/Swup.min.js"></script><script src="/js/libs/SwupSlideTheme.min.js"></script><script src="/js/libs/SwupScriptsPlugin.min.js"></script><script src="/js/libs/SwupProgressPlugin.min.js"></script><script src="/js/libs/SwupScrollPlugin.min.js"></script><script src="/js/libs/SwupPreloadPlugin.min.js"></script><script>const swup=new Swup({plugins:[new SwupScriptsPlugin({optin:!0}),new SwupProgressPlugin,new SwupScrollPlugin({offset:80}),new SwupSlideTheme({mainElement:".main-content-body"}),new SwupPreloadPlugin],containers:["#swup"]})</script><script src="/js/tools/imageViewer.js" type="module"></script><script src="/js/utils.js" type="module"></script><script src="/js/main.js" type="module"></script><script src="/js/layouts/navbarShrink.js" type="module"></script><script src="/js/tools/scrollTopBottom.js" type="module"></script><script src="/js/tools/lightDarkSwitch.js" type="module"></script><script src="/js/layouts/categoryList.js" type="module"></script><script src="/js/tools/localSearch.js" type="module"></script><script src="/js/tools/codeBlock.js" type="module"></script><script src="/js/layouts/lazyload.js" type="module"></script><script src="/js/tools/runtime.js"></script><script src="/js/libs/odometer.min.js"></script><link rel="stylesheet" href="/assets/odometer-theme-minimal.css"><script src="/js/libs/Typed.min.js"></script><script src="/js/plugins/typed.js" type="module"></script><div class="post-scripts" data-swup-reload-script><script src="/js/tools/tocToggle.js" type="module"></script><script src="/js/layouts/toc.js" type="module"></script><script src="/js/plugins/tabs.js" type="module"></script></div><div id="aplayer"></div><script src="/js/libs/APlayer.min.js"></script><script src="/js/plugins/aplayer.js"></script></body></html>